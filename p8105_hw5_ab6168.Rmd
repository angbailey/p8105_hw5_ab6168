---
title: "p8105_hw5_ab6168"
author: "Angelica Bailey"
date: "2025-11-05"
output: github_document
---

```{r, message=FALSE}
library(tidyverse)
library(broom)
set.seed(1)
```


## Problem 1

Writing function:
```{r}
#n: number of people in the group
#return true if at least two people share a birthday, false otherwise

birthday_match = function(n) {
  #randomly drawing n birthdays from 1 to 365
  birthdays = sample(1:365, size = n, replace = TRUE) 
  
  return(any(duplicated(birthdays)))
}

```


Creating data frame
```{r}
simulation_results = data.frame(
  group_size = 2:50,
  probability = numeric(length(group_size)) #initialize column of zeros
)
```

Running simulations
```{r}
for (i in 1:nrow(simulation_results)) {

  n = simulation_results$group_size[i] #getting group size n for the current row
  trials = replicate(10000, birthday_match(n)) 
  simulation_results$probability[i] = mean(trials) #calculating probability by finding the mean
}
```

Making plot
```{r}
ggplot(simulation_results, aes(x = group_size, y = probability)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  labs(
    title = "The Birthday Problem: Simulation Results",
    subtitle = paste("Based on 10,000 trials per group size"),
    x = "Number of People in Group",
    y = "Probability of at Least One Shared Birthday"
  )
```

Based on this plot, we can see that the probability of at least two people in the group sharing a birthday steadily increases as the number of people in the group increases and almost 100% chance when there are 50 people in a group.


## Problem 2

Setting design elements
```{r}
n_sample = 30        
sigma = 5       
mu = c(0,1,2,3,4,5,6)     
n_sims = 5000
alpha_level = 0.05 

#function to save test output for each dataset
sim_mean_p = function(n, mu, sigma) {
  
  sim_data = rnorm(n = n, mean = mu, sd = sigma)
  result = t.test(sim_data, mu = 0)
  
  return(broom::tidy(result))
}

#iterating for 5000 datasets for each mu
sim_results = map_dfr(mu, function(mu_value) {
  sims_mu_value = map_dfr(1:n_sims, 
                          ~sim_mean_p(
                            n = n_sample,
                            mu = mu_value,
                            sigma = sigma
  )) |> 
    mutate(mu = mu_value)
  
}) |> 
  select(mu, estimate, p.value)

```



Making plot for Power of Test vs. True value of Mean
```{r}
#calculating power for each mu
power_results = sim_results |> 
  group_by(mu) |> 
  summarize(
    power = mean(p.value < alpha_level),
    .groups = "drop"
  )

ggplot(power_results, aes(x = mu, y = power)) +
  geom_line(linewidth = 1, color = "darkgreen") +
  geom_point(size = 3, color = "darkgreen") +
  labs(
    title = "Power of One-Sample T-Test vs. True Mu",
    x = "True Population Mean (μ)",
    y = "Power"
  )

```

The plot shows a strong, positive association between effect size and power. As $\mu$ increases, the power  increases rapidly. The power increases slowly at first (from $\mu=0$ to $\mu=1$), then very steeply (from $\mu=1$ to $\mu=4$), and finally approaches 100% as the effect size becomes very large.



Making plot for average estimate of mean vs. true value of mean

```{r}
#calculating both average estimates
avg_estimates = sim_results |> 
  group_by(mu) |> 
  summarize(
    avg_mu_hat = mean(estimate), #all sims
    avg_mu_hat_rejected = mean(estimate[p.value < alpha_level]), #rejected sims
    .groups = "drop"
  )

#tidying data for plotting
plot_data = avg_estimates |> 
  pivot_longer(
    cols = c(avg_mu_hat, avg_mu_hat_rejected),
    names_to = "estimate_type",
    values_to = "avg_mu_hat"
  )

#creating plot
ggplot(plot_data,
       aes(x = mu, y = avg_mu_hat, color = estimate_type)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  
  scale_color_brewer(palette = "Set2", 
                     labels = c("All Samples", "Rejected Samples")) +
  labs(
    title = "Average Estimate (μ̂) vs. True Mean (μ)",
    x = "True Population Mean (μ)",
    y = "Average Sample Estimate (μ̂)",
    color = "Estimate Group"
  )
```

The sample average of mu across tests for which the null is rejected is not equal to the true value of mu. From the plot, we can see that the average estimate of mu in samples for which the null was rejected is higher than the true mu when the true mu is small. This happens because when we are only looking at the estimates from rejected tests, we are looking at the significant results that may overestimate the true effect, especially when the power is low.



## Problem 3

Reading in data
```{r}
homicide_data = read.csv("data/homicide-data.csv")
```


**Description of raw data:**
There are `r nrow(homicide_data)`observations with each row representing a homicide victim. The data includes the city and state where the homicide occurred, whether an arrest was made, and basic demographic information about each victim. 


```{r}
#creating new variable
homicide_data = homicide_data |> 
  mutate(city_state = str_c(city, ", ", state))

unsolved = c("Closed without arrest","Open/No arrest")

#homicide counts
city_summary = homicide_data |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% unsolved)
  )

```


Baltimore proportion test
```{r}
baltimore_data = city_summary |> 
  filter(city_state == "Baltimore, MD")

unsolved_count = baltimore_data |> pull(unsolved_homicides)
total_count = baltimore_data |> pull(total_homicides)

#running test
prop_test = prop.test(x = unsolved_count, n = total_count)

#tidying results
results = prop_test |> 
  tidy() |> 
  select(estimate, conf.low, conf.high)


```


Running test for all cities
```{r}
city_proportions = city_summary |> 
  mutate(
    prop_test_output = map2(
      .x = unsolved_homicides, 
      .y = total_homicides, 
      .f = ~ prop.test(x = .x, n = .y)
    )
  ) |> 
  mutate(
    output = map(prop_test_output, tidy)
  ) |> 
  unnest(output) |> 
  select(
    city_state,
    estimate,
    conf.low,
    conf.high
  )

city_proportions

```



Creating plot
```{r, fig.height = 7}
city_proportions |> 
  mutate(city_state = reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.2) +
  geom_point(color = "red") +
  coord_flip() +
  labs(
    title = "Estimated Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated proportion of unsolved homicides"
  )
    labs(
    title = "Estimated Proportion of Unsolved Homicides by City (95% CI)",
    subtitle = "Cities are ordered by the estimated proportion (lowest to highest)",
    x = "City",
    y = "Estimated Proportion of Unsolved Homicides"
  )
  
```





